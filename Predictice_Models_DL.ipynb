{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc09257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbab167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "def train_data(name):\n",
    "    data = all_stock_data[all_stock_data['ticker'] == name]\n",
    "    ts = data['close']\n",
    "    train = ts[:int(0.8*(len(ts)))]\n",
    "    return train\n",
    "\n",
    "def test_data(name): \n",
    "    data = all_stock_data[all_stock_data['ticker'] == name]\n",
    "    ts = data['close']\n",
    "    test = ts[int(0.8*(len(ts))):]\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe55bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c669ef0",
   "metadata": {},
   "source": [
    "# 1. Recurrent Neural Networks (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05f4961",
   "metadata": {},
   "source": [
    "# 2. Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eebef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import Dropout\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f14443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LSTM(name,number_days_predict):  \n",
    "    # Reshape the train data into a 2D array\n",
    "    train_reshaped = np.array(train_data(name)).reshape(-1, 1)\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    # Fit the scaler on the training data and transform it\n",
    "    train_scaled = scaler.fit_transform(train_reshaped)\n",
    "\n",
    "    timesteps = 12\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(timesteps, train_data(name).shape[0]):\n",
    "        X_train.append(train_scaled[i-timesteps:i, 0])  \n",
    "        y_train.append(train_scaled[i, 0]) \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    \n",
    "    seed(2019)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = 50))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "    # Fitting the RNN to the Training set\n",
    "    model.fit(X_train, y_train, epochs = 200, batch_size = 32)\n",
    "    model_lstm = model\n",
    "    \n",
    "    # Convert numpy arrays to pandas Series\n",
    "    series_train = pd.Series(train_data(name))\n",
    "    series_test = pd.Series(test_data(name))\n",
    "\n",
    "    # Combine the Series\n",
    "    combine = pd.concat([series_train, series_test], axis=0)\n",
    "    # Prepare test inputs\n",
    "    test_inputs = combine[len(combine) - len(test_data(name)) - timesteps:].values\n",
    "    test_inputs = test_inputs.reshape(-1,1)\n",
    "    test_inputs = scaler.transform(test_inputs)\n",
    "\n",
    "    # same steps as we followed while processing training data\n",
    "    X_test = []\n",
    "    for i in range(timesteps, test_data(name).shape[0]+timesteps):\n",
    "        X_test.append(test_inputs[i-timesteps:i, 0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    predicted_dead = model_lstm.predict(X_test)\n",
    "    \n",
    "    # inverse_transform because prediction is done on scaled inputs\n",
    "    \n",
    "    y_pred_LSTM = scaler.inverse_transform(predicted_dead)\n",
    "\n",
    "    # Calculate error metrics\n",
    "    mape_LSTM = mean_absolute_percentage_error(test_data(name), y_pred_LSTM)\n",
    "\n",
    "    # Lấy dữ liệu từ ngày gần nhất trong dữ liệu hiện có\n",
    "    \n",
    "    latest_data = combine[-30:].values\n",
    "    latest_data = latest_data.reshape(-1, 1)\n",
    "    latest_data = scaler.transform(latest_data)\n",
    "\n",
    "    # Chuẩn bị dữ liệu đầu vào cho mô hình LSTM\n",
    "    X_latest = latest_data.reshape(1, 30, 1)\n",
    "    predicted_next_values = []\n",
    "\n",
    "    # Dự đoán cho n ngày tiếp theo\n",
    "    for _ in range(number_days_predict):\n",
    "        # Dự đoán giá trị tiếp theo\n",
    "        next_value = model_lstm.predict(X_latest)\n",
    "        predicted_next_values.append(next_value[0, 0])\n",
    "\n",
    "        # Cập nhật dữ liệu đầu vào cho lần dự đoán tiếp theo\n",
    "        X_latest = np.roll(X_latest, -1)  # Dịch phải một bước\n",
    "        X_latest[0, -1, 0] = next_value  # Cập nhật giá trị cuối cùng bằng giá trị dự đoán mới\n",
    "\n",
    "    # Chuyển đổi lại các giá trị dự đoán thành đơn vị gốc\n",
    "    Future_Price = scaler.inverse_transform(np.array(predicted_next_values).reshape(-1, 1))\n",
    "    \n",
    "    return Future_Price[number_days_predict-1] , mape_LSTM, y_pred_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TESTING\n",
    "y_pred_LSTM = []\n",
    "Future_Price, mape_LSTM, y_pred_LSTM = model_LSTM('PHR', 7)\n",
    "print(Future_Price)\n",
    "print(mape_LSTM)\n",
    "print(y_pred_LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c977b",
   "metadata": {},
   "source": [
    "# 3. Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9207c",
   "metadata": {},
   "source": [
    "# 4. Transformer Models (e.g., Temporal Fusion Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1dc256",
   "metadata": {},
   "source": [
    "# 5. Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83031a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
